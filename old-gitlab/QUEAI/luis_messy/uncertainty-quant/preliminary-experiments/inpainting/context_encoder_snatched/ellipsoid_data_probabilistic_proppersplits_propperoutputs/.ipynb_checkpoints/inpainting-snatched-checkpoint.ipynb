{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from context_encoder_WORKING import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 64)        640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 16385     \n",
      "=================================================================\n",
      "Total params: 387,841\n",
      "Trainable params: 386,945\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 32)   320         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 64, 64, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 32)   128         leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   18496       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 128)  73856       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 16, 16, 128)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 128)  512         leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 512)    66048       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 8, 8, 512)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8, 8, 512)    0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 512)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 128)  589952      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16, 16, 128)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 128)  512         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 64)   73792       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 64)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 64)   256         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 1)    577         batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 1)    577         batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 1)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 1)    0           conv2d_11[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 825,282\n",
      "Trainable params: 824,450\n",
      "Non-trainable params: 832\n",
      "__________________________________________________________________________________________________\n",
      "Getting and resizing train images and masks ... \n",
      "Done with #  0\n",
      "Done with #  500\n",
      "Done with #  1000\n",
      "Done with #  1500\n",
      "0.8915083543144884\n",
      "-0.8851911192492561\n",
      "Getting and resizing val images and masks ... \n",
      "Done with #  0\n",
      "Getting and resizing test images and masks ... \n",
      "Done with #  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oala/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815.5874\n",
      "44.312767\n",
      "2.502261e-05\n",
      "0 [D loss: 0.003022, acc: 100.00%] [G loss: -916.371460, exp-dist-loss: -916.371460]\n",
      "val-results\n",
      "[G loss: -7817.593750, exp-dist-loss: -7817.593750]\n",
      "0.05188835\n",
      "1.070294e-05\n",
      "9.487769e-08\n",
      "50 [D loss: 0.000081, acc: 100.00%] [G loss: -4538.997070, exp-dist-loss: -4538.997070]\n",
      "val-results\n",
      "[G loss: -14411.888672, exp-dist-loss: -14411.888672]\n",
      "0.012661267\n",
      "6.945142e-06\n",
      "5.745832e-10\n",
      "100 [D loss: 0.000009, acc: 100.00%] [G loss: -4558.096191, exp-dist-loss: -4558.096191]\n",
      "val-results\n",
      "[G loss: -14395.481445, exp-dist-loss: -14395.481445]\n",
      "0.006513995\n",
      "2.464582e-06\n",
      "1.1999972e-12\n",
      "150 [D loss: 0.000002, acc: 100.00%] [G loss: -4572.343262, exp-dist-loss: -4572.343262]\n",
      "val-results\n",
      "[G loss: -14385.838867, exp-dist-loss: -14385.838867]\n",
      "0.00227435\n",
      "6.728228e-06\n",
      "6.231182e-13\n",
      "200 [D loss: 0.000009, acc: 100.00%] [G loss: -4584.570312, exp-dist-loss: -4584.570312]\n",
      "val-results\n",
      "[G loss: -14382.830078, exp-dist-loss: -14382.830078]\n",
      "0.0008834014\n",
      "6.0025745e-06\n",
      "1.1489697e-13\n",
      "250 [D loss: 0.000002, acc: 100.00%] [G loss: -4581.580078, exp-dist-loss: -4581.580078]\n",
      "val-results\n",
      "[G loss: -14376.537109, exp-dist-loss: -14376.537109]\n",
      "0.0005605897\n",
      "5.5491078e-06\n",
      "1.0117882e-14\n",
      "300 [D loss: 0.000018, acc: 100.00%] [G loss: -4597.166504, exp-dist-loss: -4597.166504]\n",
      "val-results\n",
      "[G loss: -14367.830078, exp-dist-loss: -14367.830078]\n",
      "0.00035478277\n",
      "2.5838697e-06\n",
      "3.563927e-14\n",
      "350 [D loss: 0.000001, acc: 100.00%] [G loss: -4595.400879, exp-dist-loss: -4595.400879]\n",
      "val-results\n",
      "[G loss: -14366.244141, exp-dist-loss: -14366.244141]\n",
      "0.00015393962\n",
      "3.0476654e-06\n",
      "1.1075997e-16\n",
      "400 [D loss: 0.000000, acc: 100.00%] [G loss: -4598.645020, exp-dist-loss: -4598.645020]\n",
      "val-results\n",
      "[G loss: -14372.467773, exp-dist-loss: -14372.467773]\n",
      "8.572199e-05\n",
      "8.596622e-07\n",
      "4.8112097e-17\n",
      "450 [D loss: 0.000001, acc: 100.00%] [G loss: -4600.401367, exp-dist-loss: -4600.401367]\n",
      "val-results\n",
      "[G loss: -14364.540039, exp-dist-loss: -14364.540039]\n",
      "6.2456755e-05\n",
      "5.924543e-07\n",
      "6.7202567e-19\n",
      "500 [D loss: 0.000001, acc: 100.00%] [G loss: -4604.840332, exp-dist-loss: -4604.840332]\n",
      "val-results\n",
      "[G loss: -14356.181641, exp-dist-loss: -14356.181641]\n",
      "4.9893613e-05\n",
      "1.1360649e-05\n",
      "1.5824628e-19\n",
      "550 [D loss: 0.000000, acc: 100.00%] [G loss: -4609.853027, exp-dist-loss: -4609.853027]\n",
      "val-results\n",
      "[G loss: -14360.318359, exp-dist-loss: -14360.318359]\n",
      "1.9161023e-05\n",
      "2.6639677e-07\n",
      "9.479155e-24\n",
      "600 [D loss: 0.000000, acc: 100.00%] [G loss: -4608.409668, exp-dist-loss: -4608.409668]\n",
      "val-results\n",
      "[G loss: -14360.728516, exp-dist-loss: -14360.728516]\n",
      "1.7408951e-05\n",
      "1.0727562e-06\n",
      "2.777357e-22\n",
      "650 [D loss: 0.000000, acc: 100.00%] [G loss: -4608.654297, exp-dist-loss: -4608.654297]\n",
      "val-results\n",
      "[G loss: -14357.477539, exp-dist-loss: -14357.477539]\n",
      "2.106654e-05\n",
      "7.271689e-06\n",
      "2.095291e-23\n",
      "700 [D loss: 0.000000, acc: 100.00%] [G loss: -4610.264648, exp-dist-loss: -4610.264648]\n",
      "val-results\n",
      "[G loss: -14335.443359, exp-dist-loss: -14335.443359]\n",
      "6.5267523e-06\n",
      "5.90991e-07\n",
      "2.111957e-24\n",
      "750 [D loss: 0.000001, acc: 100.00%] [G loss: -4612.496094, exp-dist-loss: -4612.496094]\n",
      "val-results\n",
      "[G loss: -14354.653320, exp-dist-loss: -14354.653320]\n",
      "9.181752e-06\n",
      "2.729481e-07\n",
      "1.6523892e-26\n",
      "800 [D loss: 0.000000, acc: 100.00%] [G loss: -4614.563477, exp-dist-loss: -4614.563477]\n",
      "val-results\n",
      "[G loss: -14359.443359, exp-dist-loss: -14359.443359]\n",
      "1.0447592e-05\n",
      "3.9315472e-07\n",
      "2.495567e-31\n",
      "850 [D loss: 0.000000, acc: 100.00%] [G loss: -4612.408691, exp-dist-loss: -4612.408691]\n",
      "val-results\n",
      "[G loss: -14352.098633, exp-dist-loss: -14352.098633]\n",
      "4.9350956e-06\n",
      "2.8488904e-07\n",
      "3.6534448e-28\n",
      "900 [D loss: 0.000000, acc: 100.00%] [G loss: -4611.233398, exp-dist-loss: -4611.233398]\n",
      "val-results\n",
      "[G loss: -14354.784180, exp-dist-loss: -14354.784180]\n",
      "8.614568e-06\n",
      "9.58739e-07\n",
      "1.1333928e-26\n",
      "950 [D loss: 0.000000, acc: 100.00%] [G loss: -4615.299316, exp-dist-loss: -4615.299316]\n",
      "val-results\n",
      "[G loss: -14360.237305, exp-dist-loss: -14360.237305]\n",
      "2.2491886e-05\n",
      "2.301488e-06\n",
      "2.8352296e-28\n",
      "1000 [D loss: 0.000002, acc: 100.00%] [G loss: -4615.453125, exp-dist-loss: -4615.453125]\n",
      "val-results\n",
      "[G loss: -14352.287109, exp-dist-loss: -14352.287109]\n",
      "7.159603e-06\n",
      "2.1642276e-07\n",
      "3.0433095e-30\n",
      "1050 [D loss: 0.000000, acc: 100.00%] [G loss: -4615.604492, exp-dist-loss: -4615.604492]\n",
      "val-results\n",
      "[G loss: -14351.513672, exp-dist-loss: -14351.513672]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1100 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oala/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/oala/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:29: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "1150 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1200 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1250 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1300 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1350 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1400 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1450 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1500 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1550 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1600 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1650 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1700 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1750 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1800 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1850 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1900 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "1950 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "val-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n",
      "test-results\n",
      "[G loss: inf, exp-dist-loss: inf]\n"
     ]
    }
   ],
   "source": [
    "context_encoder = ContextEncoder()\n",
    "context_encoder.train(epochs=2000, batch_size=64, sample_interval=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_encoder.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
