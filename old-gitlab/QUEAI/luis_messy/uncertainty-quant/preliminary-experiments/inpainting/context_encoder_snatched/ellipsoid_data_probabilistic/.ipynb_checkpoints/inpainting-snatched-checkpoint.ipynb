{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from context_encoder_WORKING import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 64)        640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 16385     \n",
      "=================================================================\n",
      "Total params: 387,841\n",
      "Trainable params: 386,945\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 32)   320         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 64, 64, 32)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 32)   128         leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 64)   18496       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 32, 32, 64)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 128)  73856       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 16, 16, 128)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 128)  512         leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 8, 8, 512)    66048       batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 8, 8, 512)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8, 8, 512)    0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 16, 16, 512)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 128)  589952      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 16, 16, 128)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 128)  512         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 32, 32, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 64)   73792       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 64)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 64)   256         activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 1)    577         batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 1)    577         batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 1)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 1)    0           conv2d_11[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 825,282\n",
      "Trainable params: 824,450\n",
      "Non-trainable params: 832\n",
      "__________________________________________________________________________________________________\n",
      "Getting and resizing train images and masks ... \n",
      "Done with #  0\n",
      "Done with #  500\n",
      "Done with #  1000\n",
      "Done with #  1500\n",
      "0.8915083543144884\n",
      "-0.8851911192492561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oala/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:478: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129752.33\n",
      "1.0284494\n",
      "0.96801883\n",
      "0 [D loss: 1.356408, acc: 28.91%] [G loss: 7.680973, exp-dist-loss: 7.687632]\n",
      "2985.7656\n",
      "13.29699\n",
      "2.2492562e-05\n",
      "200 [D loss: 0.000144, acc: 100.00%] [G loss: -3896.639648, exp-dist-loss: -3900.549805]\n",
      "1.0722018\n",
      "4.0267012e-05\n",
      "8.719184e-07\n",
      "400 [D loss: 0.000206, acc: 100.00%] [G loss: -4549.806641, exp-dist-loss: -4554.371094]\n",
      "0.37263814\n",
      "1.8482533e-05\n",
      "3.0343176e-07\n",
      "600 [D loss: 0.000120, acc: 100.00%] [G loss: -4573.378906, exp-dist-loss: -4577.963379]\n",
      "0.20195633\n",
      "8.808744e-06\n",
      "1.755986e-07\n",
      "800 [D loss: 0.000085, acc: 100.00%] [G loss: -4579.175293, exp-dist-loss: -4583.766602]\n",
      "0.12905133\n",
      "5.1292036e-06\n",
      "8.900686e-08\n",
      "1000 [D loss: 0.000078, acc: 100.00%] [G loss: -4580.205566, exp-dist-loss: -4584.801270]\n",
      "0.09282144\n",
      "7.619465e-06\n",
      "6.76314e-08\n",
      "1200 [D loss: 0.000233, acc: 100.00%] [G loss: -4583.301758, exp-dist-loss: -4587.898438]\n",
      "0.07242305\n",
      "2.3083212e-05\n",
      "6.2381666e-08\n",
      "1400 [D loss: 0.000050, acc: 100.00%] [G loss: -4588.397949, exp-dist-loss: -4593.004883]\n",
      "0.05723757\n",
      "8.648192e-06\n",
      "2.522544e-08\n",
      "1600 [D loss: 0.009307, acc: 100.00%] [G loss: -4589.663086, exp-dist-loss: -4594.264160]\n",
      "0.048751198\n",
      "5.6942013e-06\n",
      "1.9957554e-08\n",
      "1800 [D loss: 0.000223, acc: 100.00%] [G loss: -4592.750488, exp-dist-loss: -4597.363770]\n",
      "0.03629104\n",
      "3.0276044e-06\n",
      "5.9943677e-09\n",
      "2000 [D loss: 0.000196, acc: 100.00%] [G loss: -4596.078613, exp-dist-loss: -4600.693359]\n",
      "0.03303598\n",
      "2.8651198e-06\n",
      "4.513107e-09\n",
      "2200 [D loss: 0.000196, acc: 100.00%] [G loss: -4598.265625, exp-dist-loss: -4602.880859]\n",
      "0.025548313\n",
      "4.9559203e-06\n",
      "2.431826e-09\n",
      "2400 [D loss: 0.000095, acc: 100.00%] [G loss: -4603.261719, exp-dist-loss: -4607.884277]\n",
      "0.023967631\n",
      "2.425109e-06\n",
      "4.253506e-09\n",
      "2600 [D loss: 0.000136, acc: 100.00%] [G loss: -4603.193359, exp-dist-loss: -4607.816895]\n",
      "0.020555083\n",
      "2.1983312e-06\n",
      "8.7994473e-10\n",
      "2800 [D loss: 0.000150, acc: 100.00%] [G loss: -4606.070312, exp-dist-loss: -4610.696777]\n",
      "0.017890448\n",
      "3.398986e-06\n",
      "3.186402e-10\n",
      "3000 [D loss: 0.000094, acc: 100.00%] [G loss: -4607.217773, exp-dist-loss: -4611.842773]\n",
      "0.016593317\n",
      "4.8317165e-06\n",
      "2.8677302e-10\n",
      "3200 [D loss: 0.000062, acc: 100.00%] [G loss: -4605.898438, exp-dist-loss: -4610.524902]\n",
      "0.017180704\n",
      "4.8748766e-06\n",
      "2.0173038e-10\n",
      "3400 [D loss: 0.001708, acc: 100.00%] [G loss: -4606.812988, exp-dist-loss: -4611.438965]\n",
      "0.011432051\n",
      "3.0268886e-06\n",
      "7.0206944e-11\n",
      "3600 [D loss: 0.000408, acc: 100.00%] [G loss: -4608.538574, exp-dist-loss: -4613.161621]\n",
      "0.00926371\n",
      "2.2073248e-06\n",
      "1.3425484e-10\n",
      "3800 [D loss: 0.000217, acc: 100.00%] [G loss: -4611.870117, exp-dist-loss: -4616.501953]\n",
      "0.008310951\n",
      "3.2661916e-05\n",
      "3.99437e-11\n",
      "4000 [D loss: 0.000081, acc: 100.00%] [G loss: -4613.235352, exp-dist-loss: -4617.865723]\n",
      "0.0077326745\n",
      "2.1367657e-06\n",
      "3.5339863e-11\n",
      "4200 [D loss: 0.000139, acc: 100.00%] [G loss: -4615.383301, exp-dist-loss: -4620.017578]\n",
      "0.0066185226\n",
      "2.480316e-06\n",
      "1.4013644e-11\n",
      "4400 [D loss: 0.000078, acc: 100.00%] [G loss: -4613.968750, exp-dist-loss: -4618.600586]\n",
      "0.0052598254\n",
      "1.3691299e-06\n",
      "2.6551498e-12\n",
      "4600 [D loss: 0.000091, acc: 100.00%] [G loss: -4613.944336, exp-dist-loss: -4618.573242]\n",
      "0.005600515\n",
      "1.4771923e-06\n",
      "1.3546966e-11\n",
      "4800 [D loss: 0.000052, acc: 100.00%] [G loss: -4617.448730, exp-dist-loss: -4622.085449]\n",
      "0.0048034443\n",
      "2.4866445e-06\n",
      "9.578172e-12\n",
      "5000 [D loss: 0.000026, acc: 100.00%] [G loss: -4619.887207, exp-dist-loss: -4624.526855]\n",
      "0.004671375\n",
      "9.213067e-06\n",
      "6.136042e-12\n",
      "5200 [D loss: 0.000946, acc: 100.00%] [G loss: -4619.312012, exp-dist-loss: -4623.947266]\n",
      "0.0031077822\n",
      "3.7333907e-06\n",
      "9.274386e-12\n",
      "5400 [D loss: 0.000158, acc: 100.00%] [G loss: -4619.404785, exp-dist-loss: -4624.041016]\n",
      "0.003718233\n",
      "6.002826e-06\n",
      "2.7259857e-12\n",
      "5600 [D loss: 0.000211, acc: 100.00%] [G loss: -4617.731934, exp-dist-loss: -4622.367676]\n",
      "0.0030643172\n",
      "2.6972302e-06\n",
      "4.5426185e-12\n",
      "5800 [D loss: 0.000161, acc: 100.00%] [G loss: -4622.801758, exp-dist-loss: -4627.441895]\n",
      "0.0026190649\n",
      "1.3089477e-05\n",
      "3.0407551e-12\n",
      "6000 [D loss: 0.000065, acc: 100.00%] [G loss: -4620.955566, exp-dist-loss: -4625.593750]\n",
      "0.0023136083\n",
      "3.237371e-06\n",
      "7.5803936e-13\n",
      "6200 [D loss: 0.000204, acc: 100.00%] [G loss: -4624.530762, exp-dist-loss: -4629.171875]\n",
      "0.002047003\n",
      "1.2618755e-06\n",
      "2.1839323e-13\n",
      "6400 [D loss: 0.000077, acc: 100.00%] [G loss: -4623.657715, exp-dist-loss: -4628.298340]\n",
      "0.0018037979\n",
      "2.3692342e-06\n",
      "5.7826465e-12\n",
      "6600 [D loss: 0.004533, acc: 99.61%] [G loss: -4623.827637, exp-dist-loss: -4628.470215]\n",
      "0.001488156\n",
      "1.9325344e-06\n",
      "7.070207e-13\n",
      "6800 [D loss: 0.000098, acc: 100.00%] [G loss: -4628.028320, exp-dist-loss: -4632.675781]\n",
      "0.0013200305\n",
      "1.4944994e-06\n",
      "1.8496793e-13\n",
      "7000 [D loss: 0.000012, acc: 100.00%] [G loss: -4623.002441, exp-dist-loss: -4627.645020]\n",
      "0.001271015\n",
      "2.8882275e-06\n",
      "1.8532741e-13\n",
      "7200 [D loss: 0.000015, acc: 100.00%] [G loss: -4625.518555, exp-dist-loss: -4630.163086]\n",
      "0.0011296584\n",
      "1.5509141e-06\n",
      "7.1864755e-14\n",
      "7400 [D loss: 0.000052, acc: 100.00%] [G loss: -4624.986816, exp-dist-loss: -4629.630371]\n",
      "0.00096368894\n",
      "3.2267276e-06\n",
      "1.1666715e-13\n",
      "7600 [D loss: 0.000011, acc: 100.00%] [G loss: -4628.883301, exp-dist-loss: -4633.531738]\n",
      "0.0010305906\n",
      "1.2290311e-06\n",
      "3.3180273e-13\n",
      "7800 [D loss: 0.000036, acc: 100.00%] [G loss: -4624.996582, exp-dist-loss: -4629.641113]\n",
      "0.0009562287\n",
      "1.4188919e-06\n",
      "1.0701284e-13\n",
      "8000 [D loss: 0.000014, acc: 100.00%] [G loss: -4628.777832, exp-dist-loss: -4633.426758]\n",
      "0.0008122056\n",
      "2.3277137e-06\n",
      "1.0287438e-13\n",
      "8200 [D loss: 0.000009, acc: 100.00%] [G loss: -4629.934570, exp-dist-loss: -4634.584473]\n",
      "0.0007155698\n",
      "1.5785076e-06\n",
      "5.9966626e-14\n",
      "8400 [D loss: 0.000003, acc: 100.00%] [G loss: -4629.028320, exp-dist-loss: -4633.677246]\n",
      "0.0006119203\n",
      "4.0076625e-06\n",
      "9.557012e-14\n",
      "8600 [D loss: 0.000003, acc: 100.00%] [G loss: -4628.465332, exp-dist-loss: -4633.113281]\n",
      "0.0005659676\n",
      "1.697236e-06\n",
      "2.3100139e-15\n",
      "8800 [D loss: 0.000003, acc: 100.00%] [G loss: -4628.272461, exp-dist-loss: -4632.920410]\n",
      "0.00048703043\n",
      "1.4848349e-06\n",
      "1.8163004e-15\n",
      "9000 [D loss: 0.000004, acc: 100.00%] [G loss: -4629.201172, exp-dist-loss: -4633.850098]\n",
      "0.0004834525\n",
      "1.9609877e-06\n",
      "2.1659852e-14\n",
      "9200 [D loss: 0.000003, acc: 100.00%] [G loss: -4629.404297, exp-dist-loss: -4634.053223]\n",
      "0.000441821\n",
      "9.013794e-06\n",
      "4.8557027e-16\n",
      "9400 [D loss: 0.000003, acc: 100.00%] [G loss: -4629.962402, exp-dist-loss: -4634.611816]\n",
      "0.0003605269\n",
      "7.2593416e-06\n",
      "1.5510425e-14\n",
      "9600 [D loss: 0.000001, acc: 100.00%] [G loss: -4628.576660, exp-dist-loss: -4633.225098]\n",
      "0.00036047882\n",
      "1.2098043e-05\n",
      "1.0983605e-15\n",
      "9800 [D loss: 0.000003, acc: 100.00%] [G loss: -4631.925293, exp-dist-loss: -4636.577148]\n",
      "0.0003215772\n",
      "8.1467015e-06\n",
      "6.181635e-15\n",
      "10000 [D loss: 0.000001, acc: 100.00%] [G loss: -4631.304199, exp-dist-loss: -4635.955566]\n",
      "0.00025792714\n",
      "5.813718e-06\n",
      "2.7141198e-20\n",
      "10200 [D loss: 0.000001, acc: 100.00%] [G loss: -4600.302734, exp-dist-loss: -4604.919434]\n",
      "0.00024877934\n",
      "2.6044756e-06\n",
      "4.724332e-16\n",
      "10400 [D loss: 0.000001, acc: 100.00%] [G loss: -4630.566895, exp-dist-loss: -4635.217773]\n",
      "0.00019363411\n",
      "9.885898e-07\n",
      "1.0665959e-15\n",
      "10600 [D loss: 0.000001, acc: 100.00%] [G loss: -4633.951172, exp-dist-loss: -4638.605469]\n",
      "0.00019677693\n",
      "9.189335e-07\n",
      "5.768754e-16\n",
      "10800 [D loss: 0.000036, acc: 100.00%] [G loss: -4630.662598, exp-dist-loss: -4635.313477]\n",
      "0.00018028147\n",
      "1.0715098e-06\n",
      "1.6852646e-16\n",
      "11000 [D loss: 0.000017, acc: 100.00%] [G loss: -4631.618164, exp-dist-loss: -4636.270020]\n",
      "0.00016176149\n",
      "2.5376924e-06\n",
      "4.1582174e-16\n",
      "11200 [D loss: 0.000011, acc: 100.00%] [G loss: -4629.486328, exp-dist-loss: -4634.136230]\n",
      "0.00017520356\n",
      "9.352472e-07\n",
      "1.8707268e-16\n",
      "11400 [D loss: 0.000004, acc: 100.00%] [G loss: -4632.441895, exp-dist-loss: -4637.094727]\n",
      "0.00014759004\n",
      "2.8573268e-06\n",
      "3.3187485e-17\n",
      "11600 [D loss: 0.000008, acc: 100.00%] [G loss: -4632.745605, exp-dist-loss: -4637.398926]\n",
      "0.00013980354\n",
      "3.912157e-06\n",
      "1.3927791e-18\n",
      "11800 [D loss: 0.000002, acc: 100.00%] [G loss: -4632.605469, exp-dist-loss: -4637.258301]\n",
      "0.00012207776\n",
      "3.973298e-06\n",
      "1.2314054e-16\n",
      "12000 [D loss: 0.000004, acc: 100.00%] [G loss: -4631.708008, exp-dist-loss: -4636.359863]\n",
      "0.000110644076\n",
      "5.5393605e-07\n",
      "2.5290011e-18\n",
      "12200 [D loss: 0.000003, acc: 100.00%] [G loss: -4631.831055, exp-dist-loss: -4636.482910]\n",
      "9.5383286e-05\n",
      "7.212599e-07\n",
      "1.8472622e-15\n",
      "12400 [D loss: 0.000004, acc: 100.00%] [G loss: -4632.725586, exp-dist-loss: -4637.378418]\n",
      "7.777895e-05\n",
      "5.1894546e-07\n",
      "2.2502005e-16\n",
      "12600 [D loss: 0.000045, acc: 100.00%] [G loss: -4633.805664, exp-dist-loss: -4638.459473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.433913e-05\n",
      "4.537668e-07\n",
      "3.715716e-17\n",
      "12800 [D loss: 0.000005, acc: 100.00%] [G loss: -4635.528320, exp-dist-loss: -4640.184570]\n",
      "8.237138e-05\n",
      "2.5457448e-06\n",
      "2.3438917e-18\n",
      "13000 [D loss: 0.000001, acc: 100.00%] [G loss: -4633.867676, exp-dist-loss: -4638.522461]\n",
      "6.7367066e-05\n",
      "3.2978411e-07\n",
      "4.4111443e-16\n",
      "13200 [D loss: 0.000001, acc: 100.00%] [G loss: -4634.290039, exp-dist-loss: -4638.944824]\n",
      "6.107251e-05\n",
      "4.213058e-07\n",
      "5.469962e-16\n",
      "13400 [D loss: 0.000001, acc: 100.00%] [G loss: -4635.435059, exp-dist-loss: -4640.091309]\n",
      "4.545243e-05\n",
      "3.0993323e-07\n",
      "6.193687e-18\n",
      "13600 [D loss: 0.000000, acc: 100.00%] [G loss: -4632.129395, exp-dist-loss: -4636.782227]\n",
      "5.6880293e-05\n",
      "1.9588448e-07\n",
      "3.0670333e-18\n",
      "13800 [D loss: 0.000001, acc: 100.00%] [G loss: -4636.367676, exp-dist-loss: -4641.024902]\n",
      "4.3685166e-05\n",
      "2.459483e-07\n",
      "1.633088e-19\n",
      "14000 [D loss: 0.000000, acc: 100.00%] [G loss: -4627.441406, exp-dist-loss: -4632.089355]\n",
      "4.331251e-05\n",
      "3.5135014e-07\n",
      "3.7267364e-22\n",
      "14200 [D loss: 0.000000, acc: 100.00%] [G loss: -4633.018066, exp-dist-loss: -4637.671875]\n",
      "3.7904596e-05\n",
      "4.2007653e-07\n",
      "5.380468e-19\n",
      "14400 [D loss: 0.000000, acc: 100.00%] [G loss: -4635.463867, exp-dist-loss: -4640.120117]\n",
      "3.802053e-05\n",
      "3.3347237e-07\n",
      "1.1493288e-17\n",
      "14600 [D loss: 0.000000, acc: 100.00%] [G loss: -4635.336426, exp-dist-loss: -4639.992676]\n",
      "4.1990334e-05\n",
      "2.8359955e-07\n",
      "7.274036e-20\n",
      "14800 [D loss: 0.000000, acc: 100.00%] [G loss: -4632.729004, exp-dist-loss: -4637.382324]\n",
      "2.8986278e-05\n",
      "2.1056162e-07\n",
      "1.327048e-19\n",
      "15000 [D loss: 0.000000, acc: 100.00%] [G loss: -4636.830078, exp-dist-loss: -4641.487793]\n",
      "2.7718475e-05\n",
      "1.1183505e-07\n",
      "4.0278803e-18\n",
      "15200 [D loss: 0.000000, acc: 100.00%] [G loss: -4634.747559, exp-dist-loss: -4639.402832]\n",
      "2.5770933e-05\n",
      "5.020375e-07\n",
      "1.9727151e-19\n",
      "15400 [D loss: 0.000000, acc: 100.00%] [G loss: -4636.024414, exp-dist-loss: -4640.681152]\n",
      "2.5176107e-05\n",
      "1.5611495e-07\n",
      "3.2910957e-20\n",
      "15600 [D loss: 0.000000, acc: 100.00%] [G loss: -4631.896484, exp-dist-loss: -4636.548828]\n",
      "2.7296232e-05\n",
      "1.2558355e-06\n",
      "7.710576e-19\n",
      "15800 [D loss: 0.000000, acc: 100.00%] [G loss: -4635.317871, exp-dist-loss: -4639.974121]\n",
      "1.9682566e-05\n",
      "1.4759186e-07\n",
      "1.8851661e-19\n",
      "16000 [D loss: 0.000038, acc: 100.00%] [G loss: -4637.213379, exp-dist-loss: -4641.871094]\n",
      "2.2624952e-05\n",
      "1.2274327e-07\n",
      "1.2245278e-25\n",
      "16200 [D loss: 0.000034, acc: 100.00%] [G loss: -4637.219238, exp-dist-loss: -4641.876465]\n",
      "2.25597e-05\n",
      "2.1057247e-07\n",
      "9.879938e-19\n",
      "16400 [D loss: 0.000001, acc: 100.00%] [G loss: -4637.161621, exp-dist-loss: -4641.819336]\n",
      "2.3238199e-05\n",
      "3.013942e-07\n",
      "8.249409e-23\n",
      "16600 [D loss: 0.000003, acc: 100.00%] [G loss: -4637.403809, exp-dist-loss: -4642.062012]\n",
      "2.1653324e-05\n",
      "2.1347726e-07\n",
      "3.3533546e-22\n",
      "16800 [D loss: 0.000045, acc: 100.00%] [G loss: -4635.764648, exp-dist-loss: -4640.420410]\n",
      "2.0413121e-05\n",
      "3.3609215e-06\n",
      "8.890333e-20\n",
      "17000 [D loss: 0.000003, acc: 100.00%] [G loss: -4635.366211, exp-dist-loss: -4640.022461]\n",
      "1.9150628e-05\n",
      "1.9953063e-06\n",
      "7.7057264e-26\n",
      "17200 [D loss: 0.000002, acc: 100.00%] [G loss: -4637.511719, exp-dist-loss: -4642.169922]\n",
      "1.5097265e-05\n",
      "5.7008624e-08\n",
      "5.526433e-20\n",
      "17400 [D loss: 0.000016, acc: 100.00%] [G loss: -4636.030762, exp-dist-loss: -4640.687500]\n",
      "1.3955412e-05\n",
      "3.2177377e-07\n",
      "4.8512475e-21\n",
      "17600 [D loss: 0.000001, acc: 100.00%] [G loss: -4636.948242, exp-dist-loss: -4641.605957]\n",
      "1.3973383e-05\n",
      "1.4266564e-07\n",
      "1.0134572e-21\n",
      "17800 [D loss: 0.000046, acc: 100.00%] [G loss: -4636.517578, exp-dist-loss: -4641.174805]\n",
      "1.27635985e-05\n",
      "7.158576e-08\n",
      "6.513443e-20\n",
      "18000 [D loss: 0.000001, acc: 100.00%] [G loss: -4636.205078, exp-dist-loss: -4640.861816]\n",
      "1.5339054e-05\n",
      "2.8851866e-07\n",
      "1.1773365e-28\n",
      "18200 [D loss: 0.000000, acc: 100.00%] [G loss: -4637.761230, exp-dist-loss: -4642.419922]\n",
      "1.4330271e-05\n",
      "2.4586504e-07\n",
      "9.71214e-22\n",
      "18400 [D loss: 0.000003, acc: 100.00%] [G loss: -4638.075195, exp-dist-loss: -4642.733887]\n",
      "1.3601782e-05\n",
      "2.2094486e-07\n",
      "6.1139185e-26\n",
      "18600 [D loss: 0.000001, acc: 100.00%] [G loss: -4637.729004, exp-dist-loss: -4642.387207]\n",
      "1.6032523e-05\n",
      "5.674211e-07\n",
      "6.026677e-23\n",
      "18800 [D loss: 0.000000, acc: 100.00%] [G loss: -4637.290527, exp-dist-loss: -4641.948730]\n",
      "1.5047459e-05\n",
      "9.18753e-07\n",
      "3.5972125e-22\n",
      "19000 [D loss: 0.000000, acc: 100.00%] [G loss: -4638.902344, exp-dist-loss: -4643.562012]\n",
      "1.2686425e-05\n",
      "3.1928005e-07\n",
      "2.5943549e-24\n",
      "19200 [D loss: 0.000007, acc: 100.00%] [G loss: -4639.427246, exp-dist-loss: -4644.087402]\n",
      "1.1768669e-05\n",
      "1.3671682e-07\n",
      "3.7680637e-22\n",
      "19400 [D loss: 0.000000, acc: 100.00%] [G loss: -4637.369629, exp-dist-loss: -4642.027832]\n",
      "1.2515283e-05\n",
      "1.3546826e-07\n",
      "6.3218614e-29\n",
      "19600 [D loss: 0.000000, acc: 100.00%] [G loss: -4637.741699, exp-dist-loss: -4642.400391]\n",
      "1.0201912e-05\n",
      "2.1898117e-07\n",
      "3.5777217e-24\n",
      "19800 [D loss: 0.000000, acc: 100.00%] [G loss: -4637.958008, exp-dist-loss: -4642.616699]\n",
      "1.0511388e-05\n",
      "1.09382626e-07\n",
      "1.689656e-22\n",
      "20000 [D loss: 0.000000, acc: 100.00%] [G loss: -4637.994141, exp-dist-loss: -4642.652832]\n",
      "9.740762e-06\n",
      "2.6758713e-07\n",
      "2.6461738e-21\n",
      "20200 [D loss: 0.000000, acc: 100.00%] [G loss: -4636.921875, exp-dist-loss: -4641.579590]\n",
      "1.0770426e-05\n",
      "1.021253e-06\n",
      "7.965879e-25\n",
      "20400 [D loss: 0.000000, acc: 100.00%] [G loss: -4638.232422, exp-dist-loss: -4642.891602]\n",
      "1.5781581e-05\n",
      "5.262226e-07\n",
      "8.52357e-27\n",
      "20600 [D loss: 0.000000, acc: 100.00%] [G loss: -4638.321777, exp-dist-loss: -4642.980957]\n",
      "8.169278e-06\n",
      "2.3615338e-07\n",
      "1.2293333e-27\n",
      "20800 [D loss: 0.000000, acc: 100.00%] [G loss: -4639.017578, exp-dist-loss: -4643.677246]\n",
      "9.630367e-06\n",
      "3.569552e-07\n",
      "7.817832e-24\n",
      "21000 [D loss: 0.000000, acc: 100.00%] [G loss: -4636.862793, exp-dist-loss: -4641.520508]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "21200 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oala/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/home/oala/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:29: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_minimum(a, axis, None, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "21400 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "21600 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "21800 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "22000 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "22200 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "22400 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "22600 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "22800 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "23000 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "23200 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "23400 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "23600 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "23800 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "24000 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "24200 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "24400 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "24600 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "24800 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "25000 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "25200 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "25400 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "25600 [D loss: 7.971192, acc: 0.00%] [G loss: inf, exp-dist-loss: inf]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d6419000fc78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcontext_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mContextEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcontext_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/experiments-hhi/uncertainty-quant/preliminary-experiments/context_encoder_snatched/ellipsoid_data_probabilistic/context_encoder_WORKING.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, sample_interval)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;31m# ---------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmissing_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;31m# Plot the progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2667\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2649\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "context_encoder = ContextEncoder()\n",
    "context_encoder.train(epochs=30000, batch_size=128, sample_interval=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_encoder.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
