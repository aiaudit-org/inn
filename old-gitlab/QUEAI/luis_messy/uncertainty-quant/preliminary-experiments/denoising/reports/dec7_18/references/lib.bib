
@article{bachman_data_2015,
	title = {Data {Generation} as {Sequential} {Decision} {Making}},
	author = {Bachman, Philip},
	year = {2015},
	note = {0.5},
	file = {1506.03504.pdf:/home/oala/Zotero/storage/PR7Q3IW4/1506.03504.pdf:application/pdf}
}

@article{williams_simple_1992,
	title = {Simple statistical gradient-following algorithms for connectionist reinforcement learning},
	author = {Williams, Ronald},
	year = {1992},
	note = {0.5},
	file = {williams92simple.pdf:/home/oala/Zotero/storage/I2RXFW7C/williams92simple.pdf:application/pdf}
}

@article{sutton_policy_nodate,
	title = {Policy {Gradient} {Methods} for {Reinforcement} {Learning} with {Function} {Approximation}},
	abstract = {Function approximation is essential to reinforcement learning, but the standard approach of approximating a value function and determining a policy from it has so far proven theoretically intractable. In this paper we explore an alternative approach in which the policy is explicitly represented by its own function approximator, independent of the value function, and is updated according to the gradient of expected reward with respect to the policy parameters. Williams's REINFORCE method and actor-critic methods are examples of this approach. Our main new result is to show that the gradient can be written in a form suitable for estimation from experience aided by an approximate action-value or advantage function. Using this result, we prove for the first time that a version of policy iteration with arbitrary differentiable function approximation is convergent to a locally optimal policy.},
	language = {en},
	author = {Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
	pages = {7},
	file = {Sutton et al. - Policy Gradient Methods for Reinforcement Learning.pdf:/home/oala/Zotero/storage/D84KDIE8/Sutton et al. - Policy Gradient Methods for Reinforcement Learning.pdf:application/pdf}
}

@article{zhang_adversarial_nodate,
	title = {Adversarial {Feature} {Matching} for {Text} {Generation}},
	abstract = {The Generative Adversarial Network (GAN) has achieved great success in generating realistic (realvalued) synthetic data. However, convergence issues and difﬁculties dealing with discrete data hinder the applicability of GAN to text. We propose a framework for generating realistic text via adversarial training. We employ a long shortterm memory network as generator, and a convolutional network as discriminator. Instead of using the standard objective of GAN, we propose matching the high-dimensional latent feature distributions of real and synthetic sentences, via a kernelized discrepancy metric. This eases adversarial training by alleviating the mode-collapsing problem. Our experiments show superior performance in quantitative evaluation, and demonstrate that our model can generate realistic-looking sentences.},
	language = {en},
	author = {Zhang, Yizhe and Gan, Zhe and Fan, Kai and Chen, Zhi and Henao, Ricardo and Shen, Dinghan and Carin, Lawrence},
	pages = {10},
	file = {Zhang et al. - Adversarial Feature Matching for Text Generation.pdf:/home/oala/Zotero/storage/6GHB672P/Zhang et al. - Adversarial Feature Matching for Text Generation.pdf:application/pdf}
}

@article{liu_generative_nodate,
	title = {Generative {Adversarial} {Network} for {Abstractive} {Text} {Summarization}∗},
	abstract = {In this paper, we propose an adversarial process for abstractive text summarization, in which we simultaneously train a generative model G and a discriminative model D. In particular, we build the generator G as an agent of reinforcement learning, which takes the raw text as input and predicts the abstractive summarization. We also build a discriminator which attempts to distinguish the generated summary from the ground truth summary. Extensive experiments demonstrate that our model achieves competitive ROUGE scores with the state-of-the-art methods on CNN/Daily Mail dataset. Qualitatively, we show that our model is able to generate more abstractive, readable and diverse summaries1.},
	language = {en},
	author = {Liu, Linqing and Lu, Yao and Yang, Min and Qu, Qiang and Zhu, Jia and Li, Hongyan},
	note = {read},
	pages = {3},
	file = {Liu et al. - Generative Adversarial Network for Abstractive Tex.pdf:/home/oala/Zotero/storage/7PWQXXXR/Liu et al. - Generative Adversarial Network for Abstractive Tex.pdf:application/pdf}
}

@article{yu_seqgan:_nodate,
	title = {{SeqGAN}: {Sequence} {Generative} {Adversarial} {Nets} with {Policy} {Gradient}},
	abstract = {As a new way of training generative models, Generative Adversarial Net (GAN) that uses a discriminative model to guide the training of the generative model has enjoyed considerable success in generating real-valued data. However, it has limitations when the goal is for generating sequences of discrete tokens. A major reason lies in that the discrete outputs from the generative model make it difﬁcult to pass the gradient update from the discriminative model to the generative model. Also, the discriminative model can only assess a complete sequence, while for a partially generated sequence, it is nontrivial to balance its current score and the future one once the entire sequence has been generated. In this paper, we propose a sequence generation framework, called SeqGAN, to solve the problems. Modeling the data generator as a stochastic policy in reinforcement learning (RL), SeqGAN bypasses the generator differentiation problem by directly performing gradient policy update. The RL reward signal comes from the GAN discriminator judged on a complete sequence, and is passed back to the intermediate state-action steps using Monte Carlo search. Extensive experiments on synthetic data and real-world tasks demonstrate signiﬁcant improvements over strong baselines.},
	language = {en},
	author = {Yu, Lantao and Zhang, Weinan and Wang, Jun and Yu, Yong},
	note = {read},
	pages = {11},
	file = {Yu et al. - SeqGAN Sequence Generative Adversarial Nets with .pdf:/home/oala/Zotero/storage/ZHRU89JM/Yu et al. - SeqGAN Sequence Generative Adversarial Nets with .pdf:application/pdf}
}

@misc{noauthor_generative_nodate,
	title = {Generative {Adversarial} {Networks} for {Text} • r/{MachineLearning}},
	url = {https://www.reddit.com/r/MachineLearning/comments/40ldq6/generative_adversarial_networks_for_text/},
	abstract = {What are some papers where Generative Adversarial Networks have been applied to NLP models? I see plenty for images.},
	language = {de},
	urldate = {2018-04-20},
	journal = {reddit},
	file = {Snapshot:/home/oala/Zotero/storage/DVKZDAIB/generative_adversarial_networks_for_text.html:text/html}
}

@article{goodfellow_ian_generative_2014,
	title = {Generative {Adversarial} {Nets}},
	author = {Goodfellow, Ian},
	year = {2014},
	note = {read},
	file = {1406.2661.pdf:/home/oala/Zotero/storage/GXGNE4N8/1406.2661.pdf:application/pdf}
}

@article{huszar_how_2016,
	title = {{HOW} ({NOT}) {TO} {TRAIN} {YOUR} {GENERATIVE} {MODEL}: {SCHEDULED} {SAMPLING}, {LIKELIHOOD}, {ADVERSARY}?},
	abstract = {Modern applications and progress in deep learning research have created renewed interest for generative models of text and of images. However, even today it is unclear what objective functions one should use to train and evaluate these models. In this paper we present two contributions.},
	language = {en},
	author = {Huszar, Ferenc},
	year = {2016},
	note = {read},
	pages = {9},
	file = {Huszar - 2016 - HOW (NOT) TO TRAIN YOUR GENERATIVE MODEL SCHEDULE.pdf:/home/oala/Zotero/storage/ET9ZJFIB/Huszar - 2016 - HOW (NOT) TO TRAIN YOUR GENERATIVE MODEL SCHEDULE.pdf:application/pdf}
}

@article{zhao_generating_2018,
	title = {{GENERATING} {NATURAL} {ADVERSARIAL} {EXAMPLES}},
	abstract = {Due to their complex nature, it is hard to characterize the ways in which machine learning models can misbehave or be exploited when deployed. Recent work on adversarial examples, i.e. inputs with minor perturbations that result in substantially different model predictions, is helpful in evaluating the robustness of these models by exposing the adversarial scenarios where they fail. However, these malicious perturbations are often unnatural, not semantically meaningful, and not applicable to complicated domains such as language. In this paper, we propose a framework to generate natural and legible adversarial examples that lie on the data manifold, by searching in semantic space of dense and continuous data representation, utilizing the recent advances in generative adversarial networks. We present generated adversaries to demonstrate the potential of the proposed approach for black-box classiﬁers for a wide range of applications such as image classiﬁcation, textual entailment, and machine translation. We include experiments to show that the generated adversaries are natural, legible to humans, and useful in evaluating and analyzing black-box classiﬁers.},
	language = {en},
	author = {Zhao, Zhengli and Dua, Dheeru and Singh, Sameer},
	year = {2018},
	note = {read},
	pages = {15},
	file = {Zhao et al. - 2018 - GENERATING NATURAL ADVERSARIAL EXAMPLES.pdf:/home/oala/Zotero/storage/NEKILVJV/Zhao et al. - 2018 - GENERATING NATURAL ADVERSARIAL EXAMPLES.pdf:application/pdf}
}

@article{mccann_review_2017,
	title = {A {Review} of {Convolutional} {Neural} {Networks} for {Inverse} {Problems} in {Imaging}},
	volume = {34},
	issn = {1053-5888},
	url = {http://arxiv.org/abs/1710.04011},
	doi = {10.1109/MSP.2017.2739299},
	abstract = {In this survey paper, we review recent uses of convolution neural networks (CNNs) to solve inverse problems in imaging. It has recently become feasible to train deep CNNs on large databases of images, and they have shown outstanding performance on object classiﬁcation and segmentation tasks. Motivated by these successes, researchers have begun to apply CNNs to the resolution of inverse problems such as denoising, deconvolution, super-resolution, and medical image reconstruction, and they have started to report improvements over state-of-the-art methods, including sparsity-based techniques such as compressed sensing. Here, we review the recent experimental work in these areas, with a focus on the critical design decisions: Where does the training data come from? What is the architecture of the CNN? and How is the learning problem formulated and solved? We also bring together a few key theoretical papers that offer perspective on why CNNs are appropriate for inverse problems and point to some next steps in the ﬁeld.},
	language = {en},
	number = {6},
	urldate = {2018-11-02},
	journal = {IEEE Signal Processing Magazine},
	author = {McCann, Michael T. and Jin, Kyong Hwan and Unser, Michael},
	month = nov,
	year = {2017},
	note = {read},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Electrical Engineering and Systems Science - Image and Video Processing},
	pages = {85--95},
	file = {McCann et al. - 2017 - A Review of Convolutional Neural Networks for Inve.pdf:/home/oala/Zotero/storage/Z93MK26F/McCann et al. - 2017 - A Review of Convolutional Neural Networks for Inve.pdf:application/pdf}
}

@article{adler_solving_2017,
	title = {Solving ill-posed inverse problems using iterative deep neural networks},
	volume = {33},
	issn = {0266-5611, 1361-6420},
	url = {http://stacks.iop.org/0266-5611/33/i=12/a=124007?key=crossref.65c4fa88a47e07d4789aa10592f2090c},
	doi = {10.1088/1361-6420/aa9581},
	abstract = {We propose a partially learned approach for the solution of ill-posed inverse problems with not necessarily linear forward operators. The method builds on ideas from classical regularisation theory and recent advances in deep learning to perform learning while making use of prior information about the inverse problem encoded in the forward operator, noise model and a regularising functional. The method results in a gradient-like iterative scheme, where the ‘gradient’ component is learned using a convolutional network that includes the gradients of the data discrepancy and regulariser as input in each iteration. We present results of such a partially learned gradient scheme on a nonlinear tomographic inversion problem with simulated data from both the Sheep-Logan phantom as well as a head CT. The outcome is compared against filtered backprojection and total variation reconstruction and the proposed method provides a 5.4 dB PSNR improvement over the total variation reconstruction while being significantly faster, giving reconstructions of 512 × 512 pixel images in about 0.4 s using a single graphics processing unit (GPU).},
	language = {en},
	number = {12},
	urldate = {2018-11-02},
	journal = {Inverse Problems},
	author = {Adler, Jonas and Öktem, Ozan},
	month = dec,
	year = {2017},
	pages = {124007},
	file = {Adler and Öktem - 2017 - Solving ill-posed inverse problems using iterative.pdf:/home/oala/Zotero/storage/5WIKICHD/Adler and Öktem - 2017 - Solving ill-posed inverse problems using iterative.pdf:application/pdf}
}

@article{jin_deep_2017,
	title = {Deep {Convolutional} {Neural} {Network} for {Inverse} {Problems} in {Imaging}},
	volume = {26},
	issn = {1057-7149, 1941-0042},
	url = {http://arxiv.org/abs/1611.03679},
	doi = {10.1109/TIP.2017.2713099},
	abstract = {In this paper, we propose a novel deep convolutional neural network (CNN)-based algorithm for solving ill-posed inverse problems. Regularized iterative algorithms have emerged as the standard approach to ill-posed inverse problems in the past few decades. These methods produce excellent results, but can be challenging to deploy in practice due to factors including the high computational cost of the forward and adjoint operators and the difﬁculty of hyper parameter selection. The starting point of our work is the observation that unrolled iterative methods have the form of a CNN (ﬁltering followed by point-wise non-linearity) when the normal operator (H∗H, the adjoint of H times H) of the forward model is a convolution. Based on this observation, we propose using direct inversion followed by a CNN to solve normal-convolutional inverse problems. The direct inversion encapsulates the physical model of the system, but leads to artifacts when the problem is ill-posed; the CNN combines multiresolution decomposition and residual learning in order to learn to remove these artifacts while preserving image structure. We demonstrate the performance of the proposed network in sparse-view reconstruction (down to 50 views) on parallel beam X-ray computed tomography in synthetic phantoms as well as in real experimental sinograms. The proposed network outperforms total variation-regularized iterative reconstruction for the more realistic phantoms and requires less than a second to reconstruct a 512 × 512 image on the GPU.},
	language = {en},
	number = {9},
	urldate = {2018-11-02},
	journal = {IEEE Transactions on Image Processing},
	author = {Jin, Kyong Hwan and McCann, Michael T. and Froustey, Emmanuel and Unser, Michael},
	month = sep,
	year = {2017},
	note = {read},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {4509--4522},
	file = {Jin et al. - 2017 - Deep Convolutional Neural Network for Inverse Prob.pdf:/home/oala/Zotero/storage/YX2LNWBQ/Jin et al. - 2017 - Deep Convolutional Neural Network for Inverse Prob.pdf:application/pdf}
}

@article{pathak_context_2016,
	title = {Context {Encoders}: {Feature} {Learning} by {Inpainting}},
	shorttitle = {Context {Encoders}},
	url = {http://arxiv.org/abs/1604.07379},
	abstract = {We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction. By analogy with auto-encoders, we propose Context Encoders – a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part(s). When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss. The latter produces much sharper results because it can better handle multiple modes in the output. We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures. We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classiﬁcation, detection, and segmentation tasks. Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods.},
	language = {en},
	urldate = {2018-11-02},
	journal = {arXiv:1604.07379 [cs]},
	author = {Pathak, Deepak and Krahenbuhl, Philipp and Donahue, Jeff and Darrell, Trevor and Efros, Alexei A.},
	month = apr,
	year = {2016},
	note = {arXiv: 1604.07379},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Computer Science - Graphics, Computer Science - Machine Learning},
	annote = {Comment: New results on ImageNet Generation},
	file = {Pathak et al. - 2016 - Context Encoders Feature Learning by Inpainting.pdf:/home/oala/Zotero/storage/LZRSU4AK/Pathak et al. - 2016 - Context Encoders Feature Learning by Inpainting.pdf:application/pdf}
}

@article{lucas_using_2018,
	title = {Using {Deep} {Neural} {Networks} for {Inverse} {Problems} in {Imaging}: {Beyond} {Analytical} {Methods}},
	volume = {35},
	issn = {1053-5888},
	shorttitle = {Using {Deep} {Neural} {Networks} for {Inverse} {Problems} in {Imaging}},
	url = {http://ieeexplore.ieee.org/document/8253590/},
	doi = {10.1109/MSP.2017.2760358},
	language = {en},
	number = {1},
	urldate = {2018-11-02},
	journal = {IEEE Signal Processing Magazine},
	author = {Lucas, Alice and Iliadis, Michael and Molina, Rafael and Katsaggelos, Aggelos K.},
	month = jan,
	year = {2018},
	pages = {20--36},
	file = {Lucas et al. - 2018 - Using Deep Neural Networks for Inverse Problems in.pdf:/home/oala/Zotero/storage/Q2BCWA7S/Lucas et al. - 2018 - Using Deep Neural Networks for Inverse Problems in.pdf:application/pdf}
}

@article{jin_deep_2017-1,
	title = {Deep {Convolutional} {Neural} {Network} for {Inverse} {Problems} in {Imaging}},
	volume = {26},
	issn = {1057-7149, 1941-0042},
	url = {http://ieeexplore.ieee.org/document/7949028/},
	doi = {10.1109/TIP.2017.2713099},
	abstract = {In this paper, we propose a novel deep convolutional neural network (CNN)-based algorithm for solving ill-posed inverse problems. Regularized iterative algorithms have emerged as the standard approach to ill-posed inverse problems in the past few decades. These methods produce excellent results, but can be challenging to deploy in practice due to factors including the high computational cost of the forward and adjoint operators and the difﬁculty of hyperparameter selection. The starting point of this paper is the observation that unrolled iterative methods have the form of a CNN (ﬁltering followed by pointwise nonlinearity) when the normal operator (H∗ H, where H∗ is the adjoint of the forward imaging operator, H) of the forward model is a convolution. Based on this observation, we propose using direct inversion followed by a CNN to solve normal-convolutional inverse problems. The direct inversion encapsulates the physical model of the system, but leads to artifacts when the problem is ill posed; the CNN combines multiresolution decomposition and residual learning in order to learn to remove these artifacts while preserving image structure. We demonstrate the performance of the proposed network in sparse-view reconstruction (down to 50 views) on parallel beam X-ray computed tomography in synthetic phantoms as well as in real experimental sinograms. The proposed network outperforms total variation-regularized iterative reconstruction for the more realistic phantoms and requires less than a second to reconstruct a 512 × 512 image on the GPU.},
	language = {en},
	number = {9},
	urldate = {2018-12-07},
	journal = {IEEE Transactions on Image Processing},
	author = {Jin, Kyong Hwan and McCann, Michael T. and Froustey, Emmanuel and Unser, Michael},
	year = {2017},
	pages = {4509--4522},
	file = {Jin et al. - 2017 - Deep Convolutional Neural Network for Inverse Prob.pdf:/home/oala/Zotero/storage/3GXW3MST/Jin et al. - 2017 - Deep Convolutional Neural Network for Inverse Prob.pdf:application/pdf}
}

@article{gast_lightweight_2018,
	title = {Lightweight {Probabilistic} {Deep} {Networks}},
	url = {http://arxiv.org/abs/1805.11327},
	abstract = {Even though probabilistic treatments of neural networks have a long history, they have not found widespread use in practice. Sampling approaches are often too slow already for simple networks. The size of the inputs and the depth of typical CNN architectures in computer vision only compound this problem. Uncertainty in neural networks has thus been largely ignored in practice, despite the fact that it may provide important information about the reliability of predictions and the inner workings of the network. In this paper, we introduce two lightweight approaches to making supervised learning with probabilistic deep networks practical: First, we suggest probabilistic output layers for classiﬁcation and regression that require only minimal changes to existing networks. Second, we employ assumed density ﬁltering and show that activation uncertainties can be propagated in a practical fashion through the entire network, again with minor changes. Both probabilistic networks retain the predictive power of the deterministic counterpart, but yield uncertainties that correlate well with the empirical error induced by their predictions. Moreover, the robustness to adversarial examples is signiﬁcantly increased.},
	language = {en},
	urldate = {2018-12-07},
	journal = {arXiv:1805.11327 [cs, stat]},
	author = {Gast, Jochen and Roth, Stefan},
	month = may,
	year = {2018},
	note = {arXiv: 1805.11327},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: To appear at CVPR 2018},
	file = {Gast and Roth - 2018 - Lightweight Probabilistic Deep Networks.pdf:/home/oala/Zotero/storage/FLZRYQV3/Gast and Roth - 2018 - Lightweight Probabilistic Deep Networks.pdf:application/pdf}
}

@article{gal_dropout_2015,
	title = {Dropout as a {Bayesian} {Approximation}: {Representing} {Model} {Uncertainty} in {Deep} {Learning}},
	shorttitle = {Dropout as a {Bayesian} {Approximation}},
	url = {http://arxiv.org/abs/1506.02142},
	abstract = {Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classiﬁcation do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs –extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacriﬁcing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout’s uncertainty. Various network architectures and nonlinearities are assessed on tasks of regression and classiﬁcation, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and ﬁnish by using dropout’s uncertainty in deep reinforcement learning.},
	language = {en},
	urldate = {2018-12-07},
	journal = {arXiv:1506.02142 [cs, stat]},
	author = {Gal, Yarin and Ghahramani, Zoubin},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.02142},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: 12 pages, 6 figures; fixed a mistake with standard error and added a new table with updated results (marked "Update [October 2016]"); Published in ICML 2016},
	file = {Gal and Ghahramani - 2015 - Dropout as a Bayesian Approximation Representing .pdf:/home/oala/Zotero/storage/TUW77JNN/Gal and Ghahramani - 2015 - Dropout as a Bayesian Approximation Representing .pdf:application/pdf}
}