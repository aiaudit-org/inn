{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from unet_prob import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 64) 640         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 512, 512, 64) 36928       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512, 512, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 512, 512, 64) 36928       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 512, 512, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256, 256, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 256, 128 147584      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 256, 128 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 128, 128, 128 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 256 295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128, 128, 256 1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 256 590080      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128, 128, 256 1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 64, 64, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 512)  2359808     batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 64, 512)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 512)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 1024) 4719616     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 1024) 4096        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 1024) 9438208     batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 1024) 4096        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 1024) 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 1024) 0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 512)  4719104     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 512)  2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 1024) 0           dropout_1[0][0]                  \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 512)  2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 512)  2359808     batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 512 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 256 524544      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 128, 256 1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 512 0           batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 256 1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 256 590080      batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 128, 128, 256 1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 256 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 128 295040      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 256, 256, 128 512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 256 0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 128 295040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 256, 256, 128 512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 128 147584      batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 256, 256, 128 512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 512, 512, 128 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 512, 512, 64) 73792       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 512, 512, 64) 256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 512, 512, 128 0           batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 512, 512, 64) 256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 512, 512, 64) 36928       batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 512, 512, 64) 256         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 512, 512, 1)  65          batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 512, 512, 1)  2           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 512, 512, 1)  0           conv2d_25[0][0]                  \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 512, 512, 1)  2           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 512, 512, 1)  2           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 512, 512, 2)  0           conv2d_26[0][0]                  \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 33,921,415\n",
      "Trainable params: 33,907,591\n",
      "Non-trainable params: 13,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet_prob = Unet_Prob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing train images and masks ... \n",
      "Done with #  0\n",
      "Done with #  500\n",
      "Done with #  1000\n",
      "Done with #  1500\n",
      "Getting and resizing train images and masks ... \n",
      "Done with #  0\n",
      "Done with #  500\n",
      "Done with #  1000\n",
      "Done with #  1500\n",
      "Getting and resizing train images and masks ... \n",
      "Done with #  0\n",
      "Getting and resizing train images and masks ... \n",
      "Done with #  0\n"
     ]
    }
   ],
   "source": [
    "#get data\n",
    "TRAIN_PATH_IN = '/media/oala/4TB/DATA/experiments-hhi/uncertainty-quant/ellipsoid-toy/denoising/train/in/'\n",
    "VAL_PATH_IN = '/media/oala/4TB/DATA/experiments-hhi/uncertainty-quant/ellipsoid-toy/denoising/val/in/'\n",
    "TEST_PATH_IN = '/media/oala/4TB/DATA/experiments-hhi/uncertainty-quant/ellipsoid-toy/denoising/test/in/'\n",
    "\n",
    "TRAIN_PATH_REF = '/media/oala/4TB/DATA/experiments-hhi/uncertainty-quant/ellipsoid-toy/denoising/train/ref/'\n",
    "VAL_PATH_REF = '/media/oala/4TB/DATA/experiments-hhi/uncertainty-quant/ellipsoid-toy/denoising/val/ref/'\n",
    "TEST_PATH_REF = '/media/oala/4TB/DATA/experiments-hhi/uncertainty-quant/ellipsoid-toy/denoising/test/ref/'\n",
    "\n",
    "\n",
    "def get_data(path):\n",
    "    TRAIN_PATH = path\n",
    "    train_names = next(os.walk(TRAIN_PATH))[2]\n",
    "    X_train = np.zeros((len(train_names), 512, 512), dtype=np.uint16)\n",
    "    print('Getting and resizing train images and masks ... ')\n",
    "    for image_name, count in zip(train_names, range(len(train_names))):\n",
    "        img = imread(TRAIN_PATH + image_name)\n",
    "        #img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "        X_train[count] = img\n",
    "        if count % 500 == 0:\n",
    "            print('Done with # ', count)\n",
    "    X_train = X_train[:,:,:,np.newaxis]\n",
    "    \n",
    "    return X_train\n",
    "\n",
    "X_train = get_data(TRAIN_PATH_IN)\n",
    "Y_train = get_data(TRAIN_PATH_REF)\n",
    "\n",
    "X_val = get_data(VAL_PATH_IN)\n",
    "Y_val = get_data(VAL_PATH_REF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale 0 to 1\n",
    "X_train = X_train / 65535.\n",
    "Y_train = Y_train / 65535.\n",
    "X_val = X_val / 65535.\n",
    "Y_val = Y_val / 65535."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0 1.0 0.0\n",
      "1.0 0.0 1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.amax(X_train), np.amin(X_train), np.amax(Y_train), np.amin(Y_train))\n",
    "print(np.amax(X_val), np.amin(X_val), np.amax(Y_val), np.amin(Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 of 70\n",
      "Train loss: 224307.10625\n",
      "Took 11.720386028289795 seconds\n",
      "\n",
      "\n",
      "term1:  -245920.31\n",
      "term2_nume (sum):  58074309.15836717\n",
      "term2_denom (sum):  1.7123465e+33\n",
      "term2_sum:  10753430349.061699\n",
      "term2_sqrt:  103698.74805927841\n",
      "final_loss:  -14222.15644407216\n",
      "Epoch 1 of 70\n",
      "Train loss: 185657.209375\n",
      "Took 4.4197328090667725 seconds\n",
      "\n",
      "\n",
      "term1:  -67977.586\n",
      "term2_nume (sum):  40246264.31112452\n",
      "term2_denom (sum):  1.539291e+31\n",
      "term2_sum:  2749718684.6968656\n",
      "term2_sqrt:  52437.76010373503\n",
      "final_loss:  -1553.9825833764967\n",
      "Epoch 2 of 70\n",
      "Train loss: 172392.1625\n",
      "Took 4.43518328666687 seconds\n",
      "\n",
      "\n",
      "term1:  -287727.38\n",
      "term2_nume (sum):  31530088.275431287\n",
      "term2_denom (sum):  2.7189261e+29\n",
      "term2_sum:  2987205156.297145\n",
      "term2_sqrt:  54655.33053872371\n",
      "final_loss:  -23307.20444612763\n",
      "Epoch 3 of 70\n",
      "Train loss: 162476.76015625\n",
      "Took 4.466156959533691 seconds\n",
      "\n",
      "\n",
      "term1:  -162970.47\n",
      "term2_nume (sum):  25982172.979100432\n",
      "term2_denom (sum):  3.470477e+28\n",
      "term2_sum:  1952994517.7195907\n",
      "term2_sqrt:  44192.69756101782\n",
      "final_loss:  -11877.777118898219\n",
      "Epoch 4 of 70\n",
      "Train loss: 153307.29375\n",
      "Took 4.468612432479858 seconds\n",
      "\n",
      "\n",
      "term1:  -45636.97\n",
      "term2_nume (sum):  22324145.91031817\n",
      "term2_denom (sum):  7.795225e+27\n",
      "term2_sum:  540832531.4373587\n",
      "term2_sqrt:  23255.806402646173\n",
      "final_loss:  -2238.116234735383\n",
      "Epoch 5 of 70\n",
      "Train loss: 144316.38671875\n",
      "Took 4.4751856327056885 seconds\n",
      "\n",
      "\n",
      "term1:  35128.914\n",
      "term2_nume (sum):  19352735.645265486\n",
      "term2_denom (sum):  4.665864e+26\n",
      "term2_sum:  171636700.3519503\n",
      "term2_sqrt:  13101.01905776609\n",
      "final_loss:  4822.993312026609\n",
      "Epoch 6 of 70\n",
      "Train loss: 135364.86875\n",
      "Took 4.484561920166016 seconds\n",
      "\n",
      "\n",
      "term1:  56368.832\n",
      "term2_nume (sum):  17211717.91998741\n",
      "term2_denom (sum):  4.2019908e+25\n",
      "term2_sum:  88377578.21582787\n",
      "term2_sqrt:  9400.93496498236\n",
      "final_loss:  6576.976699623236\n",
      "Epoch 7 of 70\n",
      "Train loss: 126354.90546875\n",
      "Took 4.486892938613892 seconds\n",
      "\n",
      "\n",
      "term1:  71715.72\n",
      "term2_nume (sum):  15828892.094077315\n",
      "term2_denom (sum):  1.0969985e+25\n",
      "term2_sum:  59863888.12335629\n",
      "term2_sqrt:  7737.175720077468\n",
      "final_loss:  7945.289447007747\n",
      "Epoch 8 of 70\n",
      "Train loss: 117236.15859375\n",
      "Took 4.806090831756592 seconds\n",
      "\n",
      "\n",
      "term1:  56453.09\n",
      "term2_nume (sum):  14842119.277944854\n",
      "term2_denom (sum):  4.0651908e+24\n",
      "term2_sum:  45345896.26257803\n",
      "term2_sqrt:  6733.936164130013\n",
      "final_loss:  6318.702600788001\n",
      "Epoch 9 of 70\n",
      "Train loss: 107993.06484375\n",
      "Took 4.876605749130249 seconds\n",
      "\n",
      "\n",
      "term1:  33655.996\n",
      "term2_nume (sum):  13437102.579658814\n",
      "term2_denom (sum):  4.7740184e+23\n",
      "term2_sum:  37381602.6943269\n",
      "term2_sqrt:  6114.049614970989\n",
      "final_loss:  3977.0045708720986\n",
      "Epoch 10 of 70\n",
      "Train loss: 98590.13515625\n",
      "Took 4.847278594970703 seconds\n",
      "\n",
      "\n",
      "term1:  -31371.816\n",
      "term2_nume (sum):  12455008.398348033\n",
      "term2_denom (sum):  5.160385e+22\n",
      "term2_sum:  32822440.468024235\n",
      "term2_sqrt:  5729.087228173807\n",
      "final_loss:  -2564.2729178076197\n",
      "Epoch 11 of 70\n",
      "Train loss: 89020.96875\n",
      "Took 4.868715524673462 seconds\n",
      "\n",
      "\n",
      "term1:  -52122.133\n",
      "term2_nume (sum):  11155826.292825526\n",
      "term2_denom (sum):  3.3861305e+21\n",
      "term2_sum:  29157523.57037429\n",
      "term2_sqrt:  5399.770696092038\n",
      "final_loss:  -4672.236211640796\n",
      "Epoch 12 of 70\n",
      "Train loss: 79278.231640625\n",
      "Took 4.8499836921691895 seconds\n",
      "\n",
      "\n",
      "term1:  -145685.4\n",
      "term2_nume (sum):  10436669.085617455\n",
      "term2_denom (sum):  4.2710218e+20\n",
      "term2_sum:  27477510.01065929\n",
      "term2_sqrt:  5241.899465905397\n",
      "final_loss:  -14044.35067840946\n",
      "Epoch 13 of 70\n",
      "Train loss: 69343.583984375\n",
      "Took 4.868440866470337 seconds\n",
      "\n",
      "\n",
      "term1:  -227484.86\n",
      "term2_nume (sum):  9953219.400319679\n",
      "term2_denom (sum):  9.275714e+19\n",
      "term2_sum:  25603351.427079227\n",
      "term2_sqrt:  5059.975437398805\n",
      "final_loss:  -22242.48839376012\n",
      "Epoch 14 of 70\n",
      "Train loss: 59205.3470703125\n",
      "Took 4.8756022453308105 seconds\n",
      "\n",
      "\n",
      "term1:  -261289.69\n",
      "term2_nume (sum):  9344569.184162967\n",
      "term2_denom (sum):  2.2528083e+19\n",
      "term2_sum:  23299570.04474756\n",
      "term2_sqrt:  4826.962817833545\n",
      "final_loss:  -25646.272468216644\n",
      "Epoch 15 of 70\n",
      "Train loss: 48859.33623046875\n",
      "Took 4.872858285903931 seconds\n",
      "\n",
      "\n",
      "term1:  -333666.44\n",
      "term2_nume (sum):  8631015.828747362\n",
      "term2_denom (sum):  4.2797775e+18\n",
      "term2_sum:  22681480.953573134\n",
      "term2_sqrt:  4762.507842888359\n",
      "final_loss:  -32890.392965711166\n",
      "Epoch 16 of 70\n",
      "Train loss: 38304.67141113281\n",
      "Took 4.871455192565918 seconds\n",
      "\n",
      "\n",
      "term1:  -425331.22\n",
      "term2_nume (sum):  8053789.03815128\n",
      "term2_denom (sum):  8.376053e+17\n",
      "term2_sum:  22547888.02949135\n",
      "term2_sqrt:  4748.46164873334\n",
      "final_loss:  -42058.27571012666\n",
      "Epoch 17 of 70\n",
      "Train loss: 27535.028564453125\n",
      "Took 4.87373161315918 seconds\n",
      "\n",
      "\n",
      "term1:  -531162.94\n",
      "term2_nume (sum):  7745988.118129072\n",
      "term2_denom (sum):  2.7014527e+17\n",
      "term2_sum:  21876344.828361005\n",
      "term2_sqrt:  4677.215499457023\n",
      "final_loss:  -52648.5722000543\n",
      "Epoch 18 of 70\n",
      "Train loss: 16544.127551269532\n",
      "Took 4.870280742645264 seconds\n",
      "\n",
      "\n",
      "term1:  -596373.0\n",
      "term2_nume (sum):  7326276.753990122\n",
      "term2_denom (sum):  8.070765e+16\n",
      "term2_sum:  21108497.472871676\n",
      "term2_sqrt:  4594.398488689425\n",
      "final_loss:  -59177.860151131055\n",
      "Epoch 19 of 70\n",
      "Train loss: 5328.748516845703\n",
      "Took 4.866701126098633 seconds\n",
      "\n",
      "\n",
      "term1:  -639873.94\n",
      "term2_nume (sum):  7009100.6064944025\n",
      "term2_denom (sum):  3.7035134e+16\n",
      "term2_sum:  19221525.216132786\n",
      "term2_sqrt:  4384.235990013857\n",
      "final_loss:  -63548.97015099862\n",
      "Epoch 20 of 70\n",
      "Train loss: -6118.2859375\n",
      "Took 4.864826440811157 seconds\n",
      "\n",
      "\n",
      "term1:  -696315.0\n",
      "term2_nume (sum):  6618415.512764465\n",
      "term2_denom (sum):  1.0005415e+16\n",
      "term2_sum:  18530352.738414764\n",
      "term2_sqrt:  4304.689621612081\n",
      "final_loss:  -69201.0310378388\n",
      "Epoch 21 of 70\n",
      "Train loss: -17800.526318359374\n",
      "Took 4.874901294708252 seconds\n",
      "\n",
      "\n",
      "term1:  -772819.2\n",
      "term2_nume (sum):  6181689.979987152\n",
      "term2_denom (sum):  2050994400000000.0\n",
      "term2_sum:  18599537.079091094\n",
      "term2_sqrt:  4312.718061627852\n",
      "final_loss:  -76850.64694383722\n",
      "Epoch 22 of 70\n",
      "Train loss: -29714.448107910157\n",
      "Took 4.876393556594849 seconds\n",
      "\n",
      "\n",
      "term1:  -873040.75\n",
      "term2_nume (sum):  6009757.169525554\n",
      "term2_denom (sum):  882568600000000.0\n",
      "term2_sum:  18455943.50399637\n",
      "term2_sqrt:  4296.038117148912\n",
      "final_loss:  -86874.47118828511\n",
      "Epoch 23 of 70\n",
      "Train loss: -41873.92158203125\n",
      "Took 4.873698711395264 seconds\n",
      "\n",
      "\n",
      "term1:  -953952.5\n",
      "term2_nume (sum):  5790490.5585629055\n",
      "term2_denom (sum):  368452530000000.0\n",
      "term2_sum:  18220261.195354857\n",
      "term2_sqrt:  4268.519789734476\n",
      "final_loss:  -94968.39802102654\n",
      "Epoch 24 of 70\n",
      "Train loss: -54276.4443359375\n",
      "Took 4.880170583724976 seconds\n",
      "\n",
      "\n",
      "term1:  -1013172.94\n",
      "term2_nume (sum):  5496492.09513464\n",
      "term2_denom (sum):  131576160000000.0\n",
      "term2_sum:  17978842.459771775\n",
      "term2_sqrt:  4240.146513951113\n",
      "final_loss:  -100893.2790986049\n",
      "Epoch 25 of 70\n",
      "Train loss: -66935.228125\n",
      "Took 4.879115343093872 seconds\n",
      "\n",
      "\n",
      "term1:  -1114787.4\n",
      "term2_nume (sum):  5192632.456705995\n",
      "term2_denom (sum):  32249660000000.0\n",
      "term2_sum:  18750150.085444666\n",
      "term2_sqrt:  4330.144349261889\n",
      "final_loss:  -111045.7230650738\n",
      "Epoch 26 of 70\n",
      "Train loss: -79844.84140625\n",
      "Took 4.876948118209839 seconds\n",
      "\n",
      "\n",
      "term1:  -1221155.2\n",
      "term2_nume (sum):  5118494.999086074\n",
      "term2_denom (sum):  15344822000000.0\n",
      "term2_sum:  18459940.082446817\n",
      "term2_sqrt:  4296.503238966173\n",
      "final_loss:  -121685.87467610338\n",
      "Epoch 27 of 70\n",
      "Train loss: -93015.08203125\n",
      "Took 4.877285480499268 seconds\n",
      "\n",
      "\n",
      "term1:  -1311426.9\n",
      "term2_nume (sum):  4904860.339363175\n",
      "term2_denom (sum):  4268621000000.0\n",
      "term2_sum:  18969897.686422836\n",
      "term2_sqrt:  4355.444602612096\n",
      "final_loss:  -130707.14303973879\n",
      "Epoch 28 of 70\n",
      "Train loss: -106448.89765625\n",
      "Took 4.876537084579468 seconds\n",
      "\n",
      "\n",
      "term1:  -1395442.4\n",
      "term2_nume (sum):  4780070.851674309\n",
      "term2_denom (sum):  1777545900000.0\n",
      "term2_sum:  19070469.580097392\n",
      "term2_sqrt:  4366.974877429156\n",
      "final_loss:  -139107.5400122571\n",
      "Epoch 29 of 70\n",
      "Train loss: -120154.8046875\n",
      "Took 4.872932434082031 seconds\n",
      "\n",
      "\n",
      "term1:  -1536421.5\n",
      "term2_nume (sum):  4750679.983119322\n",
      "term2_denom (sum):  741325900000.0\n",
      "term2_sum:  19693553.46216539\n",
      "term2_sqrt:  4437.74193280382\n",
      "final_loss:  -153198.37580671962\n",
      "Epoch 30 of 70\n",
      "Train loss: -134131.64375\n",
      "Took 4.88204026222229 seconds\n",
      "\n",
      "\n",
      "term1:  -1637460.0\n",
      "term2_nume (sum):  4718540.287081113\n",
      "term2_denom (sum):  313297470000.0\n",
      "term2_sum:  20133435.28726143\n",
      "term2_sqrt:  4487.029673097943\n",
      "final_loss:  -163297.2970326902\n",
      "Epoch 31 of 70\n",
      "Train loss: -148392.23984375\n",
      "Took 4.871757984161377 seconds\n",
      "\n",
      "\n",
      "term1:  -1752260.5\n",
      "term2_nume (sum):  4637796.490980736\n",
      "term2_denom (sum):  129820080000.0\n",
      "term2_sum:  21275029.105831575\n",
      "term2_sqrt:  4612.486217413725\n",
      "final_loss:  -174764.80137825862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 of 70\n",
      "Train loss: -162934.07421875\n",
      "Took 4.868578910827637 seconds\n",
      "\n",
      "\n",
      "term1:  -1885672.1\n",
      "term2_nume (sum):  4699793.993032881\n",
      "term2_denom (sum):  72946860000.0\n",
      "term2_sum:  21912212.55929897\n",
      "term2_sqrt:  4681.04823296011\n",
      "final_loss:  -188099.107676704\n",
      "Epoch 33 of 70\n",
      "Train loss: -177764.3171875\n",
      "Took 4.877307653427124 seconds\n",
      "\n",
      "\n",
      "term1:  -1992504.1\n",
      "term2_nume (sum):  4677427.27854284\n",
      "term2_denom (sum):  31190802000.0\n",
      "term2_sum:  22868975.797038082\n",
      "term2_sqrt:  4782.151795691777\n",
      "final_loss:  -198772.19732043083\n",
      "Epoch 34 of 70\n",
      "Train loss: -192885.9234375\n",
      "Took 4.873394727706909 seconds\n",
      "\n",
      "\n",
      "term1:  -2086772.0\n",
      "term2_nume (sum):  4670361.320507287\n",
      "term2_denom (sum):  17384552000.0\n",
      "term2_sum:  24061591.388724815\n",
      "term2_sqrt:  4905.261602475939\n",
      "final_loss:  -208186.6738397524\n",
      "Epoch 35 of 70\n",
      "Train loss: -208303.6265625\n",
      "Took 4.879041910171509 seconds\n",
      "\n",
      "\n",
      "term1:  -2286658.8\n",
      "term2_nume (sum):  4887830.997462357\n",
      "term2_denom (sum):  10614616000.0\n",
      "term2_sum:  25405505.33112203\n",
      "term2_sqrt:  5040.387418752851\n",
      "final_loss:  -228161.8362581247\n",
      "Epoch 36 of 70\n",
      "Train loss: -224017.93125\n",
      "Took 4.870846748352051 seconds\n",
      "\n",
      "\n",
      "term1:  -2351903.5\n",
      "term2_nume (sum):  4784281.370855507\n",
      "term2_denom (sum):  3636131000.0\n",
      "term2_sum:  27898512.854251213\n",
      "term2_sqrt:  5281.904282950536\n",
      "final_loss:  -234662.15957170498\n",
      "Epoch 37 of 70\n",
      "Train loss: -240033.3515625\n",
      "Took 4.871974468231201 seconds\n",
      "\n",
      "\n",
      "term1:  -2513390.5\n",
      "term2_nume (sum):  5038967.408587787\n",
      "term2_denom (sum):  3428183600.0\n",
      "term2_sum:  28810922.494544566\n",
      "term2_sqrt:  5367.5806928768725\n",
      "final_loss:  -250802.2919307123\n",
      "Epoch 38 of 70\n",
      "Train loss: -256353.7\n",
      "Took 4.874879837036133 seconds\n",
      "\n",
      "\n",
      "term1:  -2654631.0\n",
      "term2_nume (sum):  5134304.204238267\n",
      "term2_denom (sum):  1593026800.0\n",
      "term2_sum:  31439336.087336287\n",
      "term2_sqrt:  5607.07910478676\n",
      "final_loss:  -264902.39208952134\n",
      "Epoch 39 of 70\n",
      "Train loss: -272972.3671875\n",
      "Took 4.88265061378479 seconds\n",
      "\n",
      "\n",
      "term1:  -2821874.5\n",
      "term2_nume (sum):  5420882.212926032\n",
      "term2_denom (sum):  1351992400.0\n",
      "term2_sum:  33627761.70644439\n",
      "term2_sqrt:  5798.944878720989\n",
      "final_loss:  -281607.5555121279\n",
      "Epoch 40 of 70\n",
      "Train loss: -289900.334375\n",
      "Took 4.873335123062134 seconds\n",
      "\n",
      "\n",
      "term1:  -2945239.8\n",
      "term2_nume (sum):  5526524.401199411\n",
      "term2_denom (sum):  667263800.0\n",
      "term2_sum:  36346065.9364753\n",
      "term2_sqrt:  6028.769852671049\n",
      "final_loss:  -293921.09801473294\n",
      "Epoch 41 of 70\n",
      "Train loss: -307133.709375\n",
      "Took 4.869997978210449 seconds\n",
      "\n",
      "\n",
      "term1:  -3086326.0\n",
      "term2_nume (sum):  5750072.180411579\n",
      "term2_denom (sum):  425431330.0\n",
      "term2_sum:  38973392.795238614\n",
      "term2_sqrt:  6242.86735364757\n",
      "final_loss:  -308008.3132646353\n",
      "Epoch 42 of 70\n",
      "Train loss: -324674.146875\n",
      "Took 4.880850076675415 seconds\n",
      "\n",
      "\n",
      "term1:  -3252773.0\n",
      "term2_nume (sum):  6018304.489520006\n",
      "term2_denom (sum):  242385890.0\n",
      "term2_sum:  43453767.67194675\n",
      "term2_sqrt:  6591.947183643597\n",
      "final_loss:  -324618.10528163565\n",
      "Epoch 43 of 70\n",
      "Train loss: -342525.709375\n",
      "Took 4.8758018016815186 seconds\n",
      "\n",
      "\n",
      "term1:  -3450477.2\n",
      "term2_nume (sum):  6540899.597813314\n",
      "term2_denom (sum):  291041660.0\n",
      "term2_sum:  46013251.47316402\n",
      "term2_sqrt:  6783.306824341947\n",
      "final_loss:  -344369.39431756584\n",
      "Epoch 44 of 70\n",
      "Train loss: -360683.875\n",
      "Took 4.873456239700317 seconds\n",
      "\n",
      "\n",
      "term1:  -3588648.2\n",
      "term2_nume (sum):  6692130.933199944\n",
      "term2_denom (sum):  93565100.0\n",
      "term2_sum:  52000154.707624026\n",
      "term2_sqrt:  7211.1132779636755\n",
      "final_loss:  -358143.7136722036\n",
      "Epoch 45 of 70\n",
      "Train loss: -379158.05\n",
      "Took 4.866562604904175 seconds\n",
      "\n",
      "\n",
      "term1:  -3726696.2\n",
      "term2_nume (sum):  6990964.093000524\n",
      "term2_denom (sum):  77368800.0\n",
      "term2_sum:  54990587.02518382\n",
      "term2_sqrt:  7415.5638373075735\n",
      "final_loss:  -371928.0686162693\n",
      "Epoch 46 of 70\n",
      "Train loss: -397933.478125\n",
      "Took 4.878202199935913 seconds\n",
      "\n",
      "\n",
      "term1:  -3901302.0\n",
      "term2_nume (sum):  7385489.367127674\n",
      "term2_denom (sum):  32936118.0\n",
      "term2_sum:  64690631.86593426\n",
      "term2_sqrt:  8043.048667385661\n",
      "final_loss:  -389325.89513326145\n",
      "Epoch 47 of 70\n",
      "Train loss: -417022.25\n",
      "Took 4.880449533462524 seconds\n",
      "\n",
      "\n",
      "term1:  -4115259.8\n",
      "term2_nume (sum):  7965884.586561968\n",
      "term2_denom (sum):  30564116.0\n",
      "term2_sum:  68668882.25302556\n",
      "term2_sqrt:  8286.668947956445\n",
      "final_loss:  -410697.30810520437\n",
      "Epoch 48 of 70\n",
      "Train loss: -436427.01875\n",
      "Took 4.871154069900513 seconds\n",
      "\n",
      "\n",
      "term1:  -4300698.0\n",
      "term2_nume (sum):  8422302.741675055\n",
      "term2_denom (sum):  23060656.0\n",
      "term2_sum:  75391933.58287217\n",
      "term2_sqrt:  8682.852848164142\n",
      "final_loss:  -429201.51471518364\n",
      "Epoch 49 of 70\n",
      "Train loss: -456142.0\n",
      "Took 4.8732991218566895 seconds\n",
      "\n",
      "\n",
      "term1:  -4453320.0\n",
      "term2_nume (sum):  8892991.953724235\n",
      "term2_denom (sum):  20272740.0\n",
      "term2_sum:  82702972.88802536\n",
      "term2_sqrt:  9094.117488136239\n",
      "final_loss:  -444422.58825118636\n",
      "Epoch 50 of 70\n",
      "Train loss: -476164.4875\n",
      "Took 4.872742652893066 seconds\n",
      "\n",
      "\n",
      "term1:  -4651784.0\n",
      "term2_nume (sum):  9416276.344283042\n",
      "term2_denom (sum):  10853292.0\n",
      "term2_sum:  93742740.86869833\n",
      "term2_sqrt:  9682.083498333317\n",
      "final_loss:  -464210.19165016664\n",
      "Epoch 51 of 70\n",
      "Train loss: -496497.065625\n",
      "Took 4.876073837280273 seconds\n",
      "\n",
      "\n",
      "term1:  -4839684.5\n",
      "term2_nume (sum):  10033407.981333483\n",
      "term2_denom (sum):  8979743.0\n",
      "term2_sum:  103700013.19105409\n",
      "term2_sqrt:  10183.320342160217\n",
      "final_loss:  -482950.11796578404\n",
      "Epoch 52 of 70\n",
      "Train loss: -517133.078125\n",
      "Took 4.871382474899292 seconds\n",
      "\n",
      "\n",
      "term1:  -5016512.0\n",
      "term2_nume (sum):  10582179.54928014\n",
      "term2_denom (sum):  6167188.0\n",
      "term2_sum:  118301401.50328149\n",
      "term2_sqrt:  10876.644772322092\n",
      "final_loss:  -500563.5355227678\n",
      "Epoch 53 of 70\n",
      "Train loss: -538086.86875\n",
      "Took 4.869458913803101 seconds\n",
      "\n",
      "\n",
      "term1:  -5237266.5\n",
      "term2_nume (sum):  11240194.716387171\n",
      "term2_denom (sum):  2667734.8\n",
      "term2_sum:  138754957.4077125\n",
      "term2_sqrt:  11779.429417748233\n",
      "final_loss:  -522548.7070582252\n",
      "Epoch 54 of 70\n",
      "Train loss: -559343.425\n",
      "Took 4.874286413192749 seconds\n",
      "\n",
      "\n",
      "term1:  -5370033.5\n",
      "term2_nume (sum):  11733024.233977392\n",
      "term2_denom (sum):  2718862.2\n",
      "term2_sum:  147921421.31567392\n",
      "term2_sqrt:  12162.295067777048\n",
      "final_loss:  -535787.1204932223\n",
      "Epoch 55 of 70\n",
      "Train loss: -580909.58125\n",
      "Took 4.8776373863220215 seconds\n",
      "\n",
      "\n",
      "term1:  -5720001.5\n",
      "term2_nume (sum):  13015000.41438272\n",
      "term2_denom (sum):  2044391.6\n",
      "term2_sum:  174374297.3477633\n",
      "term2_sqrt:  13205.086040907243\n",
      "final_loss:  -570679.6413959092\n",
      "Epoch 56 of 70\n",
      "Train loss: -602781.6625\n",
      "Took 4.876858472824097 seconds\n",
      "\n",
      "\n",
      "term1:  -5874623.0\n",
      "term2_nume (sum):  13536654.773219502\n",
      "term2_denom (sum):  1208417.9\n",
      "term2_sum:  198054088.1847014\n",
      "term2_sqrt:  14073.169088186974\n",
      "final_loss:  -586054.9830911814\n",
      "Epoch 57 of 70\n",
      "Train loss: -624958.76875\n",
      "Took 4.876905679702759 seconds\n",
      "\n",
      "\n",
      "term1:  -6074914.5\n",
      "term2_nume (sum):  14324265.640913568\n",
      "term2_denom (sum):  1147612.6\n",
      "term2_sum:  216625495.80570486\n",
      "term2_sqrt:  14718.202872827405\n",
      "final_loss:  -606019.6297127173\n",
      "Epoch 58 of 70\n",
      "Train loss: -647426.40625\n",
      "Took 4.869540452957153 seconds\n",
      "\n",
      "\n",
      "term1:  -6347051.5\n",
      "term2_nume (sum):  15428057.257643439\n",
      "term2_denom (sum):  872781.9\n",
      "term2_sum:  254075207.8575561\n",
      "term2_sqrt:  15939.736756218908\n",
      "final_loss:  -633111.1763243781\n",
      "Epoch 59 of 70\n",
      "Train loss: -670208.8875\n",
      "Took 4.875543117523193 seconds\n",
      "\n",
      "\n",
      "term1:  -6520103.5\n",
      "term2_nume (sum):  16109526.71127262\n",
      "term2_denom (sum):  662157.4\n",
      "term2_sum:  285343663.87357193\n",
      "term2_sqrt:  16892.118395085086\n",
      "final_loss:  -650321.1381604915\n",
      "Epoch 60 of 70\n",
      "Train loss: -693281.96875\n",
      "Took 4.875578165054321 seconds\n",
      "\n",
      "\n",
      "term1:  -6757004.0\n",
      "term2_nume (sum):  17089783.94963976\n",
      "term2_denom (sum):  527501.5\n",
      "term2_sum:  325166231.5645961\n",
      "term2_sqrt:  18032.366222007473\n",
      "final_loss:  -673897.1633777993\n",
      "Epoch 61 of 70\n",
      "Train loss: -716653.93125\n",
      "Took 4.877500534057617 seconds\n",
      "\n",
      "\n",
      "term1:  -6923049.0\n",
      "term2_nume (sum):  17780325.948419422\n",
      "term2_denom (sum):  489060.0\n",
      "term2_sum:  351541777.0546809\n",
      "term2_sqrt:  18749.44737998112\n",
      "final_loss:  -690429.9552620018\n",
      "Epoch 62 of 70\n",
      "Train loss: -740313.46875\n",
      "Took 4.866443157196045 seconds\n",
      "\n",
      "\n",
      "term1:  -7217165.5\n",
      "term2_nume (sum):  19120015.419540673\n",
      "term2_denom (sum):  484889.5\n",
      "term2_sum:  401406553.9782687\n",
      "term2_sqrt:  20035.13299127981\n",
      "final_loss:  -719713.036700872\n",
      "Epoch 63 of 70\n",
      "Train loss: -764266.5875\n",
      "Took 4.865772008895874 seconds\n",
      "\n",
      "\n",
      "term1:  -7365839.0\n",
      "term2_nume (sum):  19789294.67224362\n",
      "term2_denom (sum):  382154.34\n",
      "term2_sum:  446931696.3638928\n",
      "term2_sqrt:  21140.759124588993\n",
      "final_loss:  -734469.8240875411\n",
      "Epoch 64 of 70\n",
      "Train loss: -788500.03125\n",
      "Took 4.872127294540405 seconds\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term1:  -7592245.5\n",
      "term2_nume (sum):  20817411.60083951\n",
      "term2_denom (sum):  276075.7\n",
      "term2_sum:  516179658.68201536\n",
      "term2_sqrt:  22719.58755527959\n",
      "final_loss:  -756952.591244472\n",
      "Epoch 65 of 70\n",
      "Train loss: -813021.20625\n",
      "Took 4.873520612716675 seconds\n",
      "\n",
      "\n",
      "term1:  -7852729.5\n",
      "term2_nume (sum):  22099302.979080074\n",
      "term2_denom (sum):  268967.88\n",
      "term2_sum:  590969169.6631289\n",
      "term2_sqrt:  24309.8574587168\n",
      "final_loss:  -782841.9642541283\n",
      "Epoch 66 of 70\n",
      "Train loss: -837812.65625\n",
      "Took 4.869181156158447 seconds\n",
      "\n",
      "\n",
      "term1:  -8221158.5\n",
      "term2_nume (sum):  24011660.20223525\n",
      "term2_denom (sum):  241306.44\n",
      "term2_sum:  726311319.3784012\n",
      "term2_sqrt:  26950.163624334476\n",
      "final_loss:  -819420.8336375665\n",
      "Epoch 67 of 70\n",
      "Train loss: -862878.18125\n",
      "Took 4.868636131286621 seconds\n",
      "\n",
      "\n",
      "term1:  -8432759.0\n",
      "term2_nume (sum):  25043414.982610144\n",
      "term2_denom (sum):  205142.61\n",
      "term2_sum:  791747764.159\n",
      "term2_sqrt:  28138.01279690874\n",
      "final_loss:  -840462.0987203091\n",
      "Epoch 68 of 70\n",
      "Train loss: -888207.84375\n",
      "Took 4.876948595046997 seconds\n",
      "\n",
      "\n",
      "term1:  -8726178.0\n",
      "term2_nume (sum):  26552499.673900984\n",
      "term2_denom (sum):  162520.88\n",
      "term2_sum:  929317164.1397873\n",
      "term2_sqrt:  30484.70377320054\n",
      "final_loss:  -869569.32962268\n",
      "Epoch 69 of 70\n",
      "Train loss: -913797.36875\n",
      "Took 4.863653898239136 seconds\n",
      "\n",
      "\n",
      "term1:  -9066772.0\n",
      "term2_nume (sum):  28459743.896284275\n",
      "term2_denom (sum):  145443.8\n",
      "term2_sum:  1105928226.9383597\n",
      "term2_sqrt:  33255.49919845378\n",
      "final_loss:  -903351.6500801546\n"
     ]
    }
   ],
   "source": [
    "unet_prob.train(70, 1, X_train[0:10], Y_train[0:10], X_val[0:10], Y_val[0:10], X_val[0:10], Y_val[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unet_prob.save('unet_prob_linearmean_linearvar.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_prob.unet.load_weights('unet_prob_linearmean_linearvar.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-235f1917d88d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'conv1' is not defined"
     ]
    }
   ],
   "source": [
    "a = unet_prob.unet.get_weights(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
